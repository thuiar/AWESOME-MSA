# AWESOME-MSA
> Paper List for Multimodal Sentiment Analysis  

## Table of Contents
:monkey:[Related Repos](#related-repos)   
:monkey:[Related Datasets](#related-datasets)  
:monkey:[Related Reviews](#related-reviews)  
:monkey:[Related Conferences and Journals](#related-conferences-and-journals)   
:monkey:[Multimodal Sentiment Analysis](#multimodal-sentiment-analysis)  
:monkey:[Multimodal Emotion Recognition in Conversations](#emotion-recognition-in-conversations)  

## Related Repos
- [AWESOME-FER](https://github.com/EvelynFan/AWESOME-FER)
- [awesome-multimodal-ml](https://github.com/pliang279/awesome-multimodal-ml)
- [awesome-multimodal-research](https://github.com/Eurus-Holmes/Awesome-Multimodal-Research)
- [CMU-Multimodal-SDK](https://github.com/A2Zadeh/CMU-MultimodalSDK)
- [Multimodal-Emotion-Recognition](https://github.com/maelfabien/Multimodal-Emotion-Recognition)
- [Multimodal-Sentiment-Analysis](https://github.com/soujanyaporia/multimodal-sentiment-analysis)
- [awesome-sentiment-analysis](https://github.com/xiamx/awesome-sentiment-analysis)
- [awesome-nlp-sentiment-analysis](https://github.com/haiker2011/awesome-nlp-sentiment-analysis)

### Related Datasets
- (2020) [CH-SIMS](https://github.com/thuiar/MMSA) \[[paper](https://www.aclweb.org/anthology/2020.acl-main.343/), [code](https://github.com/thuiar/MMSA)\]
- (2019) [UR-FUNNY](https://github.com/ROC-HCI/UR-FUNNY) \[[paper](https://www.aclweb.org/anthology/D19-1211/)\]
- (2019) [MELD](http://affective-meld.github.io) \[[paper](https://www.aclweb.org/anthology/P19-1050.pdf), [code](https://github.com/SenticNet/MELD)\]
- (2018) [MOSEI](http://immortal.multicomp.cs.cmu.edu) \[[paper](https://www.aclweb.org/anthology/P18-1208.pdf)\]
- (2016) [MOSI](http://immortal.multicomp.cs.cmu.edu) \[[paper](https://arxiv.org/abs/1606.06259)\]
- (2013) [MOUD](https://web.eecs.umich.edu/~mihalcea/downloads.html) \[[paper](https://www.aclweb.org/anthology/P13-1096.pdf)\]
- (2013) [ICT-MMMO]() \[[paper](https://ieeexplore.ieee.org/abstract/document/6487473)\]
- (2011) [YouTube]() \[[paper](https://dl.acm.org/doi/pdf/10.1145/2070481.2070509)\]
- (2008) [IEMOCAP](https://sail.usc.edu/iemocap/) \[[paper](https://link.springer.com/article/10.1007/s10579-008-9076-6)\]
<!-- - () [POM](http://immortal.multicomp.cs.cmu.edu) \[[paper]()\] -->
    
### Related Reviews
- (2019) [Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods](https://arxiv.org/abs/1907.09358)
- (2019) [Multimodal Machine Learning: A Survey and Taxonomy](https://ieeexplore.ieee.org/abstract/document/8269806/)  (:bulb::bulb::bulb:)
- (2019) [Deep Multimodal Representation Learning: A Survey](https://ieeexplore.ieee.org/abstract/document/8715409/)
- (2019) [Multimodal Intelligence: Representation Learning, Information Fusion, and Applications](https://arxiv.org/abs/1911.03977)
- (2018) [Multimodal Sentiment Analysis: Addressing Key Issues and Setting up Baselines](https://ieeexplore.ieee.org/abstract/document/8636432/) 
- (2016) [Chinese Textual Sentiment Analysis: Datasets, Resources and Tools](https://www.aclweb.org/anthology/C16-3002.pdf)
- (2017) [A review of affective computing: From unimodal analysis to multimodal fusion](https://www.sciencedirect.com/science/article/pii/S1566253517300738)
- (2017) [A survey of multimodal sentiment analysis](https://www.sciencedirect.com/science/article/pii/S0262885617301191) 
- (2013) [Representation Learning: A Review and New Perspectives](https://ieeexplore.ieee.org/abstract/document/6472238/)
- (2005) [Multimodal approaches for emotion recognition: a survey](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5670/0000/Multimodal-approaches-for-emotion-recognition-a-survey/10.1117/12.600746.short)

### Related Conferences and Journals
#### Coferences
[ACL & EMNLP & NAACL & CoLing](https://www.aclweb.org/anthology/), 
[AAAI](https://www.aaai.org/Library/AAAI/aaai-library.php), 
[IJCAI](https://www.ijcai.org/proceedings/2019/), 
[ICLR](https://openreview.net/group?id=ICLR.cc/2019/Conference), 
[ICML](https://icml.cc/Conferences/2018/Schedule), 
[NeurIPS](https://nips.cc/Conferences/2018/Schedule?type=Poster), 
[ICMI](https://www.icmi.com/), 
[ACM-MM](https://2020.acmmm.org/)

#### Journals
[IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE](),
[IEEE Transactions on Multimedia](), 
[IEEE Transactions on Affective Computing](), 
[Knowledge-based System](), 
[Information Fusion](), 
[IEEE Access](), 
[IEEE Intelligent Systems](), 


### Multimodal Sentiment Analysis
---
#### Association for Computational Linguistics (ACL)
- (2020) [Integrating Multimodal Information in Large Pretrained Transformers](https://www.aclweb.org/anthology/2020.acl-main.214/) \[[code](https://github.com/WasifurRahman/BERT_multimodal_transformer)\]
- (2020) [A Recipe for Creating Multimodal Aligned Datasets for Sequential Tasks Angela](https://www.aclweb.org/anthology/2020.acl-main.440/)
- (2020) [Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis](https://www.aclweb.org/anthology/2020.acl-main.401/) \[[code](http://www.iitp.ac.in/˜ai-nlp-ml/resources.html)\]
- (2020) [CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality](https://www.aclweb.org/anthology/2020.acl-main.343/) \[[code](https://github.com/thuiar/MMSA)\]
- (2020 Workshop) [A Transformer-based joint-encoding for Emotion Recognition and Sentiment Analysis](https://www.aclweb.org/anthology/2020.challengehml-1.1.pdf) \[[code](https://www.aclweb.org/anthology/2020.challengehml-1.1.pdf)\]
- (2020 Workshop) [Low Rank Fusion based Transformers for Multimodal Sequences](https://www.aclweb.org/anthology/2020.challengehml-1.4.pdf)
- (2019) [Modality-based Factorization for Multimodal Fusion](https://www.aclweb.org/anthology/W19-4331.pdf)
- (2019) [Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing](https://www.aclweb.org/anthology/P19-1046.pdf) 
- (2019) [Multimodal and Multi­view Models for Emotion Recognition](https://www.aclweb.org/anthology/P19-1095.pdf) \[[code](https://github.com/tzirakis/Multimodal-Emotion-Recognition)\]
- (2019) [Multimodal Transformer for Unaligned Multimodal Language Sequences](https://www.aclweb.org/anthology/P19-1656.pdf) \[[code](https://github.com/yaohungt/Multimodal-Transformer)\]
- (2019) [Contextual Inter-modal Attention for Multi-modal Sentiment Analysis](https://www.aclweb.org/anthology/D18-1382.pdf) \[[code](https://github.com/soujanyaporia/contextual-multimodal-fusion)\]
- (2019) [Towards Multimodal Sarcasm Detection (An Obviously Perfect Paper)](https://www.aclweb.org/anthology/P19-1455.pdf) \[[code](https://github.com/soujanyaporia/MUStARD)\]
- (2018) [Getting the subtext without the text: Scalable multimodal sentiment classification from visual and acoustic modalities](https://www.aclweb.org/anthology/W18-3301.pdf)
- (2018) [Recognizing Emotions in Video Using Multimodal DNN Feature Fusion](https://www.aclweb.org/anthology/W18-3302.pdf) \[[code](https://github.com/rhoposit/MultimodalDNN)\]
- (2018) [Efficient Low-rank Multimodal Fusion with Modality-Specific Factors](https://www.aclweb.org/anthology/P18-1209.pdf) \[[code](https://github.com/Justin1904/Low-rank-Multimodal-Fusion)\]
- (2018) [Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment](https://www.aclweb.org/anthology/P18-1207.pdf)
- (2018) [Multimodal Relational Tensor Network for Sentiment and Emotion Classification](https://www.aclweb.org/anthology/W18-3303.pdf)
- (2018) [Sentiment Analysis using Imperfect Views from Spoken Language and Acoustic Modalities](https://www.aclweb.org/anthology/W18-3305.pdf)
- (2018) [Seq2Seq2Sentiment: Multimodal Sequence to Sequence Models for Sentiment Analysis](https://www.aclweb.org/anthology/W18-3308.pdf)
- (2018) [Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data](https://www.aclweb.org/anthology/W18-3304.pdf)
- (2018) [DNN Multimodal Fusion Techniques for Predicting Video Sentiment](https://www.aclweb.org/anthology/W18-3309.pdf)
- (2017) [Context-Dependent Sentiment Analysis in User-Generated Videos](https://www.aclweb.org/anthology/P17-1081.pdf) \[[code](https://github.com/soujanyaporia/contextual-utterance-level-multimodal-sentiment-analysis)\]
- (2017) [Multimodal Machine Learning: Integrating Language, Vision and Speech](https://www.aclweb.org/anthology/P17-5002.pdf)

#### Empirical Methods in Natural Language Processing (EMNLP)
- (2019) [Context­aware Interactive Attention for Multi­modal Sentiment and Emotion Analysis](https://www.iitp.ac.in/~ai-nlp-ml/papers/emnlp19-emotion.pdf) \[[code](https://github.com/DushyantChauhan/EMNLP-19-IIM/tree/master)\]
- (2018) [Associative Multichannel Autoencoder for Multimodal Word Representation](https://www.aclweb.org/anthology/D18-1011.pdf) \[[code](https://github.com/wangshaonan/Associative-multichannel-autoencoder)\]
- (2018) [Contextual Inter-­modal Attention for Multi­modal Sentiment Analysis](https://www.aclweb.org/anthology/D18-1382.pdf) \[[code](https://github.com/soujanyaporia/contextual-multimodal-fusion)\]
- (2018) [Importance of Self­Attention for Sentiment Analysis](https://www.aclweb.org/anthology/W18-5429.pdf)
- (2018) [Improving Multi­-label Emotion Classification via Sentiment Classification with Dual Attention Transfer Network](https://www.aclweb.org/anthology/D18-1137.pdf)
- (2017) [Tensor Fusion Network for Multimodal Sentiment Analysis](https://www.aclweb.org/anthology/D17-1115.pdf) \[[code](https://github.com/A2Zadeh/TensorFusionNetwork)\]
- (2015) [Deep Convolutional Neural Network Textual Features and Multiple Kernel Learning for Utterance­level Multimodal Sentiment Analysis](https://www.aclweb.org/anthology/D15-1303.pdf)

#### North American Chapter of the Association for Computational Linguistics (NAACL)
- (2019) [Strong and Simple Baselines for Multimodal Utterance Embeddings](https://www.aclweb.org/anthology/N19-1267.pdf) \[[code](https://github.com/yaochie/multimodal-baselines)\]
- (2019) [Quantifiers in a Multimodal World: Hallucinating Vision with Language and Sound](https://www.aclweb.org/anthology/W19-2912.pdf)
- (2019) [Multi­task Learning for Multi­modal Emotion Recognition and Sentiment Analysis](https://www.aclweb.org/anthology/N19-1034.pdf) \[[code](https://github.com/DushyantChauhan/NAACL-19-CIM)\]
- (2018) [Multimodal Emoji Prediction](https://www.aclweb.org/anthology/N18-2107.pdf)
- (2018) [Sentiment Analysis: It’s Complicated!](https://www.aclweb.org/anthology/N18-1171.pdf) \[[code](https://github.com/networkdynamics/mcgill-tsa)\]
- (2016) [Bridge Correlational Neural Networks for Multilingual Multimodal Representation Learning](https://www.aclweb.org/anthology/N16-1021.pdf)

#### International Conference on Computational Linguistics （CoLing）
- (2018) [Hybrid Attention based Multimodal Network for Spoken Language Classification](https://www.aclweb.org/anthology/C18-1201.pdf)
- (2018) [Learning Emotion­enriched Word Representations](https://www.aclweb.org/anthology/C18-1081.pdf)
- (2018) [Emotion Detection and Classification in a Multigenre Corpus with Joint Multi­Task Deep Learning](https://www.aclweb.org/anthology/C18-1246.pdf)
- (2016) [Multimodal Mood Classification ­ A Case Study of Differences in Hindi and Western Songs](https://www.aclweb.org/anthology/C16-1186.pdf)

#### Association for the Advancement of Artificial Intelligence (AAAI)
- (2019) [VistaNet: Visual Aspect Attention Network for Multimodal Sentiment Analysis](https://aaai.org/ojs/index.php/AAAI/article/view/3799) \[[code](https://github.com/PreferredAI/vista-net)\]
- (2019) [Multi-Interactive Memory Network for Aspect Based Multimodal Sentiment Analysis](https://aaai.org/ojs/index.php/AAAI/article/view/3807) \[[code](https://github.com/xunan0812/MIMN)\]
- (2019) [An Efficient Approach to Informative Feature Extraction from Multimodal Data](https://aaai.org/ojs/index.php/AAAI/article/view/4464)
- (2019) [Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors](https://www.aaai.org/ojs/index.php/AAAI/article/download/4706/4584) \[[code](https://github.com/victorywys/RAVEN)\]
- (2019) [Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities](https://wvvw.aaai.org/ojs/index.php/AAAI/article/download/4666/4544) 
- (2019) [Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion](https://www.aaai.org/Papers/AAAI/2020GB/AAAI-MaiS.10285.pdf)
- (2018) [Learning Multimodal Word Representation via Dynamic Fusion Methods](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16167/16164)
- (2018) [Predicting Depression Severity by Multi-Modal Feature Engineering and Fusion](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16415/16511)
- (2018) [Memory Fusion Network for Multi-View Sequential Learning](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPDFInterstitial/17341/16122) \[[code](https://github.com/pliang279/MFN)\]
- (2018) [Inferring Emotion from Conversational Voice Data: A Semi-Supervised Multi-Path Generative Neural Network Approach](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPDFInterstitial/17236/15735) 
- (2017) [Multimodal Fusion of EEG and Musical Features in Music-Emotion Recognition](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14831/14237)
- (2016) [Personalized Microblog Sentiment Classification via Multi-Task Learning](https://aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12031/12061)

#### International Joint Conferences on Artificial Intelligence (IJCAI)
- (2019) [Success Prediction on Crowdfunding with Multimodal Deep Learning](https://www.ijcai.org/proceedings/2019/0299.pdf)
- (2019) [AttnSense: Multi-level Attention Mechanism For Multimodal Human Activity Recognition](https://www.ijcai.org/Proceedings/2019/0431.pdf) \[[code](https://github.com/zzpustc/ML-Application-on-Network)\]
- (2019) [DeepCU: Integrating both Common and Unique Latent Information for Multimodal Sentiment Analysis](https://www.ijcai.org/Proceedings/2019/0503.pdf) \[[code](https://github.com/sverma88/DeepCU-IJCAI19)\]
- (2019) [Adapting BERT for Target-Oriented Multimodal Sentiment Classification](https://www.ijcai.org/Proceedings/2019/0751.pdf) \[[code](https://github.com/jefferyYu/TomBERT)\]
- (2019) [Multi-view Clustering via Late Fusion Alignment Maximization](https://www.ijcai.org/proceedings/2019/0524.pdf)
- (2019) [Towards Discriminative Representation Learning for Speech Emotion Recognition](https://www.ijcai.org/Proceedings/2019/0703.pdf) \[[code](https://github.com/thuhcsi/IJCAI2019-DRL4SER)\]

#### International Conference on Learning Representations (ICLR)
- (2019) [Learning Factorized Multimodal Representations](https://openreview.net/forum?id=rygqqsA9KX) \[[code](https://github.com/pliang279/factorized)\]

#### Neural Information Processing Systems (NeurIPS)
- (2018) [Learning Robust Joint Representations for Multimodal Sentiment Analysis](https://openreview.net/pdf?id=rkgx8x1js7)

#### Other
- (2020) [Factorized Multimodal Transformer for Multimodal Sequential Learning](https://openreview.net/pdf?id=BJxD11HFDS) \[[code](https://github.com/A2Zadeh/Factorized-Multimodal-Transformer)\]
- (2020) [OmniNet: A unified architecture for multi-modal multi-task learning](https://openreview.net/pdf?id=HJgdo6VFPH) \[[code](https://github.com/subho406/OmniNet), [Review](https://openreview.net/forum?id=HJgdo6VFPH)\]

<!-- #### International Conference on Machine Learning (ICML) -->

#### International Conference on Multimodal Interaction (ICMI)
- (2019) [Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement Learning](https://dl.acm.org/doi/pdf/10.1145/3136755.3136801)


### Emotion Recognition in Conversations
---
#### Association for the Advancement of Artificial Intelligence (AAAI)
- (2019) [DialogueRNN: An Attentive RNN for Emotion Detection in Conversations](https://www.aaai.org/ojs/index.php/AAAI/article/download/4657/4535) \[[code](https://github.com/SenticNet/conv-emotion)\]

#### Empirical Methods in Natural Language Processing (EMNLP)
- (2019) [DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation](https://www.aclweb.org/anthology/D19-1015/) \[[code](https://github.com/SenticNet/conv-emotion)\]
- (2018) [ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection](https://www.aclweb.org/anthology/D18-1280.pdf) \[[code](https://github.com/SenticNet/conv-emotion)\]

#### North American Chapter of the Association for Computational Linguistics (NAACL)
- (2019) [HiGRU: Hierarchical Gated Recurrent Units for Utterance-level Emotion Recognition](https://www.aclweb.org/anthology/N19-1037.pdf) \[[code](https://github.com/wxjiao/HiGRUs)\]
- (2018) [Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos](https://www.aclweb.org/anthology/N18-1193.pdf) \[[code](https://github.com/SenticNet/conv-emotion)\]

#### ACM International Conference on Multimedia (ACM MM)
- (2018) [Inferring User Emotive State Changes in Realistic Human-Computer Conversational Dialogs](https://dl.acm.org/doi/pdf/10.1145/3240508.3240575)
